// Generated by @typespec/http-server-csharp
// <auto-generated />
  #nullable enable

using System;
using System.Net;
using System.Text.Json;
using System.Text.Json.Serialization;
using System.Threading.Tasks;
using Microsoft.AspNetCore.Mvc;
using AI.Chat.Service.Models;
using TypeSpec.Helpers;
using System.Text;
using System.Threading;

namespace AI.Chat.Service
{
    /// <summary>
    /// This is a mock implementation of the business logic interface for 
    /// demonstration and early development.  Feel free to overwrite this file.
    /// Or replace it with another implementation, and register that implementation 
    /// in the dependency injection container
    /// </summary>
    /// <param name="initializer">The initializer class, registered with dependency injection</param>
    public class ChatOperations : IChatOperations
    {
        public ChatOperations(IInitializer initializer)
        {
            _initializer = initializer;
        }

        private IInitializer _initializer;

        public async Task<IActionResult> GetStreamedCompletionAsync(HttpContext context, AiChatCompletionRequest body, CancellationToken cancellationToken)
        {
            //return Task.FromResult("Hello back");

            // Set streaming headers
            context.Response.Headers.Add("Content-Type", "application/jsonl");
            context.Response.Headers.Add("Cache-Control", "no-cache");
            context.Response.Headers.Add("Connection", "keep-alive");

            for (int i = 0; i<10; i++)
            {
                var chatDelta = new AiChatMessageDelta { Content = $"Fake response {i}\r\n" };
                string json = JsonSerializer.Serialize(chatDelta);


                await context.Response.Body.WriteAsync(Encoding.UTF8.GetBytes(json), cancellationToken);
                await context.Response.Body.FlushAsync(cancellationToken);
                Thread.Sleep(100);
            }

            return new EmptyResult();
        }
    }
}
  